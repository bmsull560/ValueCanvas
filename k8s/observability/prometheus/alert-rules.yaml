apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: observability
  labels:
    app: prometheus
data:
  valuecanvas-alerts.yml: |
    groups:
    - name: valuecanvas
      interval: 30s
      rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (namespace, pod)
            /
            sum(rate(http_requests_total[5m])) by (namespace, pod)
          ) > 0.05
        for: 5m
        labels:
          severity: critical
          component: backend
        annotations:
          summary: "High error rate detected"
          description: "{{ $labels.namespace }}/{{ $labels.pod }} has error rate of {{ $value | humanizePercentage }}"

      # High response time
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, namespace, pod)
          ) > 1
        for: 5m
        labels:
          severity: warning
          component: backend
        annotations:
          summary: "High response time detected"
          description: "{{ $labels.namespace }}/{{ $labels.pod }} has p95 latency of {{ $value }}s"

      # Pod down
      - alert: PodDown
        expr: up{job="kubernetes-pods"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Pod is down"
          description: "{{ $labels.namespace }}/{{ $labels.pod }} has been down for more than 2 minutes"

      # High CPU usage
      - alert: HighCPUUsage
        expr: |
          (
            sum(rate(container_cpu_usage_seconds_total{namespace=~"valuecanvas.*"}[5m])) by (namespace, pod)
            /
            sum(container_spec_cpu_quota{namespace=~"valuecanvas.*"} / container_spec_cpu_period{namespace=~"valuecanvas.*"}) by (namespace, pod)
          ) > 0.8
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "{{ $labels.namespace }}/{{ $labels.pod }} CPU usage is {{ $value | humanizePercentage }}"

      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (
            sum(container_memory_working_set_bytes{namespace=~"valuecanvas.*"}) by (namespace, pod)
            /
            sum(container_spec_memory_limit_bytes{namespace=~"valuecanvas.*"}) by (namespace, pod)
          ) > 0.9
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "{{ $labels.namespace }}/{{ $labels.pod }} memory usage is {{ $value | humanizePercentage }}"

      # Pod restart
      - alert: PodRestarting
        expr: rate(kube_pod_container_status_restarts_total{namespace=~"valuecanvas.*"}[15m]) > 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Pod is restarting"
          description: "{{ $labels.namespace }}/{{ $labels.pod }} has restarted {{ $value }} times in the last 15 minutes"

      # Database connection pool exhausted
      - alert: DatabaseConnectionPoolExhausted
        expr: |
          (
            sum(database_connections_active) by (namespace, pod)
            /
            sum(database_connections_max) by (namespace, pod)
          ) > 0.9
        for: 5m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "{{ $labels.namespace }}/{{ $labels.pod }} is using {{ $value | humanizePercentage }} of connection pool"

      # High request rate
      - alert: HighRequestRate
        expr: sum(rate(http_requests_total[5m])) by (namespace) > 1000
        for: 5m
        labels:
          severity: info
        annotations:
          summary: "High request rate"
          description: "{{ $labels.namespace }} is receiving {{ $value }} requests/second"

    - name: kubernetes
      interval: 30s
      rules:
      # Node not ready
      - alert: NodeNotReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Node is not ready"
          description: "Node {{ $labels.node }} has been not ready for more than 5 minutes"

      # Node disk pressure
      - alert: NodeDiskPressure
        expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Node has disk pressure"
          description: "Node {{ $labels.node }} is experiencing disk pressure"

      # Node memory pressure
      - alert: NodeMemoryPressure
        expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Node has memory pressure"
          description: "Node {{ $labels.node }} is experiencing memory pressure"

      # Deployment replica mismatch
      - alert: DeploymentReplicasMismatch
        expr: |
          kube_deployment_spec_replicas{namespace=~"valuecanvas.*"}
          !=
          kube_deployment_status_replicas_available{namespace=~"valuecanvas.*"}
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Deployment replicas mismatch"
          description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has {{ $value }} replica mismatch"

      # PVC almost full
      - alert: PVCAlmostFull
        expr: |
          (
            kubelet_volume_stats_used_bytes
            /
            kubelet_volume_stats_capacity_bytes
          ) > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "PVC almost full"
          description: "PVC {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is {{ $value | humanizePercentage }} full"
